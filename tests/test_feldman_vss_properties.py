# tests/test_feldman_vss_properties.py
# Property-based tests for Feldman VSS using Hypothesis.

import copy  # noqa: I001
import secrets
import warnings

import pytest
from gmpy2 import f_mod, mpz
from hypothesis import (  # type: ignore[reportMissingImports]
    HealthCheck,
    Phase,
    Verbosity,
    assume,
    given,
    settings,
    strategies as st,
)

from feldman_vss import (
    CommitmentList,
    FeldmanVSS,
    ParameterError,
    ProofDict,
    SecurityError,
    SecurityWarning,
    SerializationError,
    ShareDict,
    VerificationError,
)

from .test_conftest import (
    TEST_PRIME_BITS_FAST,
    MockField,
    MockShamirSecretSharing,  # INFO: Only used in test_prop_refresh_preserves_secret
    generate_poly_and_shares,
    test_logger,
)

# Skip all tests in this module if Hypothesis is not installed
hypothesis = pytest.importorskip("hypothesis")


# --- Hypothesis Configuration ---

# Register profiles for different testing levels
settings.register_profile(
    "ci",
    max_examples=200,
    deadline=None,  # No deadline for CI
    verbosity=Verbosity.normal,
    phases=[Phase.explicit, Phase.reuse, Phase.generate, Phase.target, Phase.shrink],
)
settings.register_profile(
    "dev",
    max_examples=50,
    deadline=2000,  # 2 seconds deadline for dev
    verbosity=Verbosity.verbose,
)
settings.register_profile(
    "deep",
    max_examples=1000,
    deadline=None,
    verbosity=Verbosity.normal,
    phases=[Phase.explicit, Phase.reuse, Phase.generate, Phase.target, Phase.shrink],
)

# Load the desired profile (e.g., 'dev' for local runs, 'ci' for CI)
settings.load_profile("dev")

# --- Test Class ---


@pytest.mark.properties  # Custom marker for property-based tests
class TestPropertyBased:
    """Property-based tests using Hypothesis for robustness."""

    # Define strategies within the class
    # Strategy for threshold t (ensure t >= 2)
    threshold_strategy = st.integers(min_value=2, max_value=10)  # Keep max small for speed

    @staticmethod
    @st.composite
    def coeffs_and_shares_strategy(draw, field: MockField):
        """Composite strategy to generate consistent coefficients and shares."""
        t = draw(TestPropertyBased.threshold_strategy)
        # Ensure n >= t
        n = draw(st.integers(min_value=t, max_value=15))  # Keep max small
        secret = draw(st.integers(min_value=0, max_value=int(field.prime) - 1))
        # Generate coefficients using the field's random element method
        coeffs = [mpz(secret)] + [field.random_element() for _ in range(t - 1)]
        shares: ShareDict = {}
        for i in range(1, n + 1):
            x = mpz(i)
            y = field.eval_poly(coeffs, x)
            shares[i] = (x, y)
        # Return the generated coefficients, shares, threshold, and number of shares.
        return coeffs, shares, t, n

    # --- Tests ---

    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large])
    @given(st.data())  # Use st.data() to allow drawing based on fixtures
    def test_prop_verify_valid_shares(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data):
        """Property: Correctly generated shares should always verify."""
        # Pass the `mock_field_fast` fixture (providing the field context) to the strategy.
        coeffs, shares, _, _ = data.draw(self.coeffs_and_shares_strategy(field=mock_field_fast))
        # Use `_` for unused `t` and `n` variables.

        # `assume` tells Hypothesis to discard examples where the condition is false.
        assume(coeffs)  # Skip if coeffs list is empty (shouldn't happen with t>=2 but good practice).
        assume(shares)  # Skip if shares dict is empty.

        # Use a try-except block to handle expected exceptions during property-based testing.
        try:
            # Create commitments for the generated coefficients using the VSS instance.
            commitments = default_vss.create_commitments(coeffs)
            # Iterate through the generated shares.
            for share_id in shares:
                x, y = shares[share_id]
                # Assert that each valid share verifies correctly against the commitments.
                assert default_vss.verify_share(x, y, commitments) is True, f"Valid share ({x},{y}) failed verification"
        # Catch expected errors that might occur due to edge cases generated by Hypothesis.
        except (ParameterError, ValueError, SecurityError, MemoryError) as e:
            # Log the caught expected error for debugging purposes.
            test_logger.debug("Hypothesis verify valid share caught expected error: %s", e)
            # Allow the test run to continue if an expected error occurs.
        # Catch any unexpected exceptions.
        except Exception as e:
            # Fail the test immediately if an unexpected exception occurs.
            pytest.fail(f"Unexpected exception during valid share verification: {e!s}")

    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large])
    @given(st.data(), tamper_amount=st.integers(min_value=1))  # Tamper by at least 1
    def test_prop_verify_invalid_shares(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data, tamper_amount):
        """Property: Tampered shares should always fail verification."""
        # Pass the `mock_field_fast` fixture to the strategy.
        coeffs, shares, _, _ = data.draw(self.coeffs_and_shares_strategy(mock_field_fast))
        # Use `_` for unused `t` and `n` variables.

        # Assume the generated coefficients and shares are not empty.
        assume(coeffs)
        assume(shares)

        # Use try-except block for expected errors during edge case testing.
        try:
            # Create commitments for the coefficients.
            commitments = default_vss.create_commitments(coeffs)
            # Choose a random share ID to tamper with using `secrets.choice` for security.
            share_id_to_tamper = secrets.choice(list(shares.keys()))
            x, y = shares[share_id_to_tamper]

            # Tamper the y-value (share value) by adding the `tamper_amount` modulo the field prime.
            # Ensure the result is explicitly cast to `mpz`.
            invalid_y = f_mod(mpz(y) + tamper_amount, mock_field_fast.prime)
            # Assume the tampering actually changed the value.
            assume(invalid_y != y)

            # Assert that the tampered share (with invalid y) fails verification.
            assert default_vss.verify_share(x, invalid_y, commitments) is False, f"Invalid share ({x},{invalid_y}) passed verification"

            # Also test tampering the x-value (participant ID). This should also fail.
            invalid_x = x + 1  # Simple tamper: increment x.
            # Assert that the share with the tampered x-value fails verification.
            assert default_vss.verify_share(invalid_x, y, commitments) is False, (
                f"Share with invalid x ({invalid_x},{y}) passed verification"
            )

        # Catch expected errors from Hypothesis edge cases.
        except (ParameterError, ValueError, SecurityError, MemoryError) as e:
            test_logger.debug("Hypothesis verify invalid share caught expected error: %s", e)
        # Catch unexpected exceptions.
        except Exception as e:
            pytest.fail(f"Unexpected exception during invalid share verification: {e!s}")

    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large])
    @given(st.data())
    def test_prop_zkp_roundtrip(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data):
        """Property: ZKP creation and verification should succeed for valid inputs."""
        # Pass the `mock_field_fast` fixture to the strategy. Shares, t, n are not needed here.
        coeffs, _, _, _ = data.draw(self.coeffs_and_shares_strategy(mock_field_fast))
        # Assume coefficients are generated.
        assume(coeffs)

        # Use try-except for expected errors.
        try:
            # Create commitments for the coefficients.
            commitments = default_vss.create_commitments(coeffs)
            # Create a Zero-Knowledge Proof (ZKP) for the polynomial coefficients.
            proof = default_vss.create_polynomial_proof(coeffs, commitments)

            # Assert that the created proof verifies correctly against the commitments.
            assert default_vss.verify_polynomial_proof(proof, commitments) is True, "ZKP verification failed for valid proof"

            # Also test the combined verification method which includes ZKP verification.
            assert default_vss.verify_commitments_with_proof(commitments, proof) is True, "Combined ZKP verification failed"

            # Explicitly test the internal challenge consistency check as well.
            assert default_vss._verify_challenge_consistency(proof, commitments) is True, "Challenge consistency check failed"

        # Catch expected errors.
        except (ParameterError, ValueError, SecurityError, MemoryError) as e:
            test_logger.debug("Hypothesis ZKP roundtrip caught expected error: %s", e)
        # Catch unexpected exceptions.
        except Exception as e:
            pytest.fail(f"Unexpected exception during ZKP roundtrip: {e!s}")

    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large])
    @given(st.data())
    def test_prop_zkp_tampered_proof_fails(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data):
        """Property: Tampered ZKP should fail verification."""
        # Pass the `mock_field_fast` fixture to the strategy.
        coeffs, _, _, _ = data.draw(self.coeffs_and_shares_strategy(mock_field_fast))
        # Assume coefficients are generated.
        assume(coeffs)

        # Use try-except for expected errors.
        try:
            # Create commitments and a valid ZKP.
            commitments = default_vss.create_commitments(coeffs)
            proof = default_vss.create_polynomial_proof(coeffs, commitments)

            # --- Tamper with Challenge ---
            # Create a deep copy of the proof to tamper with.
            tampered_proof_c = copy.deepcopy(proof)
            # Tamper the challenge value by adding 1 modulo the field prime.
            # Explicitly cast intermediate result to `mpz` before `f_mod`.
            tampered_challenge_val = mpz(mpz(proof["challenge"]) + 1)
            tampered_proof_c["challenge"] = f_mod(tampered_challenge_val, mock_field_fast.prime)
            # Assert that the proof with the tampered challenge fails verification.
            assert default_vss.verify_polynomial_proof(tampered_proof_c, commitments) is False, "Verification passed for tampered challenge"

            # --- Tamper with a Response ---
            # Create another deep copy for tampering.
            tampered_proof_r = copy.deepcopy(proof)
            # Check if there are responses to tamper with.
            if tampered_proof_r["responses"]:
                # Choose a random response index to tamper.
                idx_to_tamper = secrets.randbelow(len(tampered_proof_r["responses"]))
                # Tamper the chosen response value by adding 1 modulo the field prime.
                # Explicitly cast intermediate result to `mpz` before `f_mod`. Break line for readability.
                tampered_response_val = mpz(mpz(proof["responses"][idx_to_tamper]) + 1)
                tampered_proof_r["responses"][idx_to_tamper] = f_mod(tampered_response_val, mock_field_fast.prime)
                # Assert that the proof with the tampered response fails verification.
                assert default_vss.verify_polynomial_proof(tampered_proof_r, commitments) is False, (
                    "Verification passed for tampered response"
                )

            # --- Tamper with a Blinding Commitment ---
            # Create another deep copy.
            tampered_proof_bc = copy.deepcopy(proof)
            # Check if there are blinding commitments to tamper with.
            if tampered_proof_bc["blinding_commitments"]:
                # Choose a random blinding commitment index.
                idx_bc = secrets.randbelow(len(tampered_proof_bc["blinding_commitments"]))
                # Extract the original blinding commitment (value, randomizer) tuple.
                orig_bc, orig_br = tampered_proof_bc["blinding_commitments"][idx_bc]
                # Tamper the blinding commitment value by adding 1 modulo the field prime.
                # Explicitly cast intermediate result to `mpz` before `f_mod`. Break line for readability.
                tampered_bc_val = mpz(mpz(orig_bc) + 1)
                # Update the proof with the tampered blinding commitment value, keeping the original randomizer.
                tampered_proof_bc["blinding_commitments"][idx_bc] = (f_mod(tampered_bc_val, mock_field_fast.prime), orig_br)
                # Assert that the proof with the tampered blinding commitment fails verification.
                assert default_vss.verify_polynomial_proof(tampered_proof_bc, commitments) is False, (
                    "Verification passed for tampered blinding commitment"
                )

        # Catch expected errors.
        except (ParameterError, ValueError, SecurityError, MemoryError) as e:
            test_logger.debug("Hypothesis ZKP tampering test caught expected error: %s", e)
        # Catch unexpected exceptions.
        except Exception as e:
            pytest.fail(f"Unexpected exception during ZKP tampering test: {e!s}")

    @settings(deadline=None, suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large])
    @given(st.data())
    def test_prop_serialization_roundtrip(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data):
        """Property: Serialization and deserialization should be lossless."""
        # Pass the `mock_field_fast` fixture to the strategy.
        coeffs, _, _, _ = data.draw(self.coeffs_and_shares_strategy(mock_field_fast))
        # Assume coefficients are generated.
        assume(coeffs)

        # Use try-except for expected errors.
        try:
            # Create commitments.
            commitments = default_vss.create_commitments(coeffs)
            # Serialize the commitments.
            serialized = default_vss.serialize_commitments(commitments)
            # Deserialize the commitments. `ts` (timestamp) is not used in assertions.
            # Use `_` for unused `ts` variable.
            deserialized, gen, prime, _, is_hash = default_vss.deserialize_commitments(serialized)

            # Assert that the deserialized generator and prime match the original VSS instance.
            assert gen == default_vss.generator
            assert prime == default_vss.group.prime
            # Assert that the commitment type is hash-based (as expected for this PQ VSS).
            assert is_hash is True
            # Assert that the number of deserialized commitments matches the original number.
            assert len(deserialized) == len(commitments)
            # Compare each component of the deserialized commitments with the original.
            for i in range(len(commitments)):
                assert deserialized[i][0] == commitments[i][0]  # Hash value
                assert deserialized[i][1] == commitments[i][1]  # Randomizer
                assert deserialized[i][2] == commitments[i][2]  # Entropy (bytes or None)

            # --- Test Serialization with Proof ---
            # Create a ZKP.
            proof = default_vss.create_polynomial_proof(coeffs, commitments)
            # Serialize commitments *with* the proof.
            serialized_with_proof = default_vss.serialize_commitments_with_proof(commitments, proof)
            # Deserialize commitments *with* the proof. Ignore generator, prime, timestamp.
            deser_comm, deser_proof, _, _, _ = default_vss.deserialize_commitments_with_proof(serialized_with_proof)

            # Assert basic properties of the deserialized commitments and proof.
            assert len(deser_comm) == len(commitments)
            assert isinstance(deser_proof, dict)
            assert deser_proof["challenge"] == proof["challenge"]
            assert len(deser_proof["responses"]) == len(proof["responses"])
            # More detailed proof comparison could be added if necessary.

        # Catch expected errors during serialization/deserialization.
        except (ParameterError, ValueError, SerializationError, SecurityError, MemoryError) as e:
            test_logger.debug("Hypothesis serialization roundtrip caught expected error: %s", e)
        # Catch unexpected exceptions.
        except Exception as e:
            pytest.fail(f"Unexpected exception during serialization roundtrip: {e!s}")

    # Configure Hypothesis settings for the share refresh test.
    @settings(
        deadline=None,
        suppress_health_check=[HealthCheck.filter_too_much, HealthCheck.data_too_large, HealthCheck.too_slow],
        max_examples=20,  # Reduce examples for refresh
    )
    @given(st.data())
    def test_prop_refresh_preserves_secret(self, default_vss: FeldmanVSS, mock_field_fast: MockField, data):
        """Property: Share refreshing should preserve the original secret."""
        # Pass the `mock_field_fast` fixture to the strategy.
        coeffs, shares, t, n = data.draw(self.coeffs_and_shares_strategy(mock_field_fast))

        # Assume coefficients are generated.
        assume(coeffs)
        # Assume there are enough shares (at least `t`) to potentially perform the refresh.
        assume(len(shares) >= t)

        # Use try-except for expected errors, especially SecurityError.
        try:
            # Create the original commitments.
            original_commitments = default_vss.create_commitments(coeffs)
            # Get the list of participant IDs from the shares dictionary.
            participant_ids = list(shares.keys())

            # Use a deep copy of the shares to avoid modifying the original dictionary.
            shares_copy = copy.deepcopy(shares)

            # Perform the share refresh operation.
            # Use `warnings.catch_warnings` to temporarily ignore `SecurityWarning`.
            with warnings.catch_warnings():
                warnings.simplefilter("ignore", SecurityWarning)
                # Call the `refresh_shares` method. `verification_data` is not used.
                # Use `_` for unused `verification_data` variable.
                new_shares, new_commitments, _ = default_vss.refresh_shares(shares_copy, t, n, original_commitments, participant_ids)

            # Verify secret reconstruction from the *new* shares using the `MockShamirSecretSharing` helper.
            shamir_mock = MockShamirSecretSharing(mock_field_fast)

            # Assume there are enough new shares (at least `t`) to reconstruct the secret.
            assume(len(new_shares) >= t)

            # Select a random subset of `t` new shares for reconstruction.
            subset_ids = secrets.SystemRandom().sample(list(new_shares.keys()), t)
            subset_shares_dict = {pid: new_shares[pid] for pid in subset_ids}

            # Reconstruct the secret from the subset of new shares.
            reconstructed_secret = shamir_mock.reconstruct_secret(subset_shares_dict)
            # Get the original secret (the first coefficient).
            original_secret = coeffs[0]

            # Assert that the reconstructed secret matches the original secret.
            assert reconstructed_secret == original_secret, "Secret not preserved after refreshing"

            # Optionally, verify that the new shares are valid against the *new* commitments.
            for share_id in new_shares:
                x, y = new_shares[share_id]
                assert default_vss.verify_share(x, y, new_commitments), "Refreshed share failed verification against new commitments"

        # Catch expected errors, particularly SecurityError if refresh fails.
        except (ParameterError, ValueError, SecurityError, MemoryError) as e:
            test_logger.debug("Hypothesis refresh secret preservation caught expected error: %s", e)
        # Catch unexpected exceptions during the complex refresh operation.
        except Exception as e:
            # Log the full exception traceback for debugging unexpected errors.
            test_logger.exception("Unexpected error during Hypothesis refresh test")
            # Fail the test.
            pytest.fail(f"Unexpected exception in refresh test: {e!s}")
